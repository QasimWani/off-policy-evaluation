{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main program on estimating error function for Off-Policy-Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install Box2D\n",
    "# !pip install 'gym[all]'\n",
    "# !pip install pyyaml\n",
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import deque, defaultdict\n",
    "\n",
    "import time\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "import yaml\n",
    "import re\n",
    "\n",
    "from dqnetwork import DQNetwork\n",
    "from agent import Agent\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from os import listdir, getcwd\n",
    "from os.path import isabs, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the environment\n",
    "env_id = 'CartPole-v0'\n",
    "env = gym.make(env_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Load Policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### get all model policies - \"../model/policies/behavior_policy_x.pth\"\n",
    "def get_policies(path, config):\n",
    "    \"\"\"\n",
    "    Loads all policies in a given directory into an agent\n",
    "    @Param:\n",
    "    1. Path - model path.\n",
    "    2. config - path for configuration of corresponding model\n",
    "    @Return:\n",
    "    - policies: list of agent\n",
    "    \"\"\"\n",
    "    cwd = getcwd() #get current working directory\n",
    "    index = lambda index : int(re.findall(r'[0-9]+', index)[-1]) #get policy number\n",
    "        \n",
    "    #Get paths for config and policy.\n",
    "    policy_files = {index(f): join(path, f) for f in listdir(join(cwd, path)) if isabs(join(cwd, f))}\n",
    "    yaml_files   = [join(cwd, join(config, f)) for f in listdir(join(cwd, config)) if isabs(join(cwd, f))]\n",
    "\n",
    "    policies = [] #loads an agent policy\n",
    "    \n",
    "    for config_file in yaml_files:\n",
    "        with open(r''+ config_file) as file:\n",
    "            config_data = yaml.load(file, Loader=yaml.FullLoader) #get output as dict\n",
    "            info = config_data[0] #gets model size info\n",
    "            num = index(config_file) #get file number\n",
    "            agent = Agent(fc1=info['fc1'], fc2=info['fc2'], path=policy_files[num])\n",
    "            policies.append( agent ) #add agent\n",
    "    return policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded into local and target networks!\n",
      "Model loaded into local and target networks!\n",
      "Model loaded into local and target networks!\n"
     ]
    }
   ],
   "source": [
    "agents = get_policies(\"../model/policies\", \"../model/config\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Get Trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trajectories(agent, N=10, render=False):\n",
    "    \"\"\"\n",
    "    Returns N trajectories for an agent, å, with behavior policy π*.\n",
    "    Expected return should be ≥ 195, otherwise, model loaded is not an expert policy.\n",
    "    @Param:\n",
    "    1. agent - (Agent) Agent object representing an expert policy.\n",
    "    2. N - number of trajectories/episodes to run.\n",
    "    3. render - (bool) render iPython gui.\n",
    "    @Return:\n",
    "    1. trajectories - State, Action, Reward, Next_State Transitions for finite Horizon, H.\n",
    "    2. Return - total reward for a single trajectory\n",
    "    \"\"\"\n",
    "    trajectories = []\n",
    "    rewards = []\n",
    "    \n",
    "    for n in range(N):\n",
    "        transitions = []\n",
    "        total_reward = 0\n",
    "        state = env.reset() #reset\n",
    "        while True:\n",
    "            action = agent.get_action(state, eps=0.01)\n",
    "            next_state, reward, done, info = env.step(action)\n",
    "            total_reward += reward\n",
    "            transitions.append((state, action, reward, next_state)) #store transition\n",
    "            state = next_state\n",
    "            if(render):\n",
    "                env.render() #display agent\n",
    "            if(done): #stopping condition\n",
    "                trajectories.append(transitions)\n",
    "                rewards.append(total_reward)\n",
    "                break\n",
    "    \n",
    "    assert(np.mean(rewards) >= 195) #condition for expert policy\n",
    "    \n",
    "    return np.array(trajectories), np.array(rewards)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 - generate policy matrix\n",
    "<p> A policy matrix is of dimensions (K, K - 1), where K is the total number of behavior policies </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_matrix(agents):\n",
    "    \"\"\"Generates policy matrix (dictionary) of shape (n, n-1) for x agents\"\"\"\n",
    "    matrix = {}\n",
    "    for i, evaluation in enumerate(agents):\n",
    "        matrix[evaluation] = []\n",
    "        for j, behavior in enumerate(agents):\n",
    "            if(i != j):\n",
    "                matrix[evaluation].append(behavior)\n",
    "    return matrix        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#each key indicates evaluation policy, and corresponding values indicate behavior policies\n",
    "policy_dict = policy_matrix(agents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_behavior_policies(evaluation_policy):\n",
    "    \"\"\"Generates respective behvaior policies for a particular evaluation policy\"\"\"\n",
    "    return policy_dict[evaluation_policy] if evaluation_policy in policy_dict else None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
